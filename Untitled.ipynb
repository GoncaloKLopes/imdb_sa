{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import settings as s\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from model import BinarySARNN\n",
    "from utils import dir_to_csv, tokenize, binary_accuracy, epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_path = os.path.join(s.DATASET_PATH, s.TRAIN_DIR)\n",
    "train_dataset_path = os.path.join(s.DATA_DIR, s.TRAIN_CSV)\n",
    "embeddings_path = os.path.join(s.DATASET_PATH, s.EMBEDDINGS_FILE)\n",
    "vocab_path = os.path.join(s.DATA_DIR, s.VOCAB_FILE)\n",
    "\n",
    "model_config = s.MODEL_CONFIG\n",
    "train_config = s.TRAIN_CONFIG\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists, skipping creation...\n",
      "Loading training set...\n",
      "Training set successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# create train set\n",
    "dir_to_csv(s.TRAIN_CSV, train_files_path)\n",
    "\n",
    "REVIEW = torchtext.data.Field(tokenize=tokenize, lower=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "print(\"Loading training set...\")\n",
    "train = torchtext.data.TabularDataset(path=train_dataset_path, format=\"CSV\",\n",
    "                                      fields=[(\"review\", REVIEW),\n",
    "                                              (\"label\", LABEL)],\n",
    "                                      csv_reader_params={\"delimiter\": \" \"})\n",
    "\n",
    "\n",
    "train_iter = torchtext.data.Iterator(train, model_config.batch_size, device=device)\n",
    "\n",
    "REVIEW.build_vocab(train)\n",
    "print(\"Training set successfully loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2 * 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings successfully loaded.\n",
      "\n",
      "vocabulary file already exists, skipping creation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load word embeddings\n",
    "print(\"Loading word embeddings...\")\n",
    "embeddings = KeyedVectors.load_word2vec_format(embeddings_path, binary=False,\n",
    "                                               unicode_errors='ignore')\n",
    "print(\"Word embeddings successfully loaded.\\n\")\n",
    "\n",
    "vocab = embeddings.vocab\n",
    "if not os.path.isfile(vocab_path):\n",
    "    print(\"Vocabulary file not present, creating...\")\n",
    "    with open(vocab_path, \"wb+\") as vf:\n",
    "        pickle.dump(vocab, vf)\n",
    "    print(\"Done.\\n\")\n",
    "else:\n",
    "    print(\"vocabulary file already exists, skipping creation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarySARNN(\n",
       "  (embed): Embedding(168994, 300)\n",
       "  (rnn): RNN(300, 128, num_layers=2, bidirectional=True)\n",
       "  (hidden_to_label): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model configurations\n",
    "model_config.vocab_size = len(embeddings.vocab)\n",
    "model_config.d_embed = embeddings.vector_size\n",
    "\n",
    "model = BinarySARNN(model_config)\n",
    "model.embed.weight.data.copy_(torch.from_numpy(embeddings.vectors))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Config\n",
      "============\n",
      "d_hidden = 128\n",
      "vocab_size = 168994\n",
      "d_embed = 300\n",
      "batch_size = 128\n",
      "n_layers = 2\n",
      "nonlin = tanh\n",
      "dropout = 0\n",
      "bidir = True\n",
      "\n",
      "Train Config\n",
      "=============\n",
      "criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "optimizer = <class 'torch.optim.adagrad.Adagrad'>\n",
      "optimizer args = {}\n",
      "epochs = 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set training configuration\n",
    "criterion = train_config.criterion()\n",
    "criterion.to(device)\n",
    "\n",
    "opt = train_config.optimizer(model.parameters(), **train_config.o_kwargs)\n",
    "\n",
    "print(str(model_config) + \"\\n\")\n",
    "print(str(train_config) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 51s\n",
      "\tTrain Loss: 0.702 | Train Acc: 50.00%\n",
      "Epoch: 02 | Epoch Time: 3m 42s\n",
      "\tTrain Loss: 0.683 | Train Acc: 57.50%\n",
      "Epoch: 03 | Epoch Time: 5m 33s\n",
      "\tTrain Loss: 0.592 | Train Acc: 52.50%\n",
      "Epoch: 04 | Epoch Time: 7m 25s\n",
      "\tTrain Loss: 0.535 | Train Acc: 52.50%\n",
      "Epoch: 05 | Epoch Time: 9m 16s\n",
      "\tTrain Loss: 0.479 | Train Acc: 55.00%\n"
     ]
    }
   ],
   "source": [
    "iterations = 0\n",
    "start = time.time()\n",
    "best_dev_acc = -1\n",
    "train_iter.repeat = False\n",
    "\n",
    "for epoch in range(train_config.epochs):\n",
    "    train_iter.init_epoch()\n",
    "\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iter):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        iterations += 1\n",
    "        #forward pass\n",
    "        answer = model(batch.review)\n",
    "        \n",
    "        #calculate accuracy in current batch\n",
    "        train_acc = binary_accuracy(torch.max(answer, 1).values, batch.label.float()).item()\n",
    "        #calculate loss\n",
    "        loss = criterion(answer, batch.label)\n",
    "\n",
    "        #backpropagate, calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #update model parameters\n",
    "        opt.step()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {loss:.3f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "\n",
    "model_fname = f\"{model_config.id}|{train_config.id}.pt\"\n",
    "torch.save(model.state_dict(), os.path.join(s.MODELS_PATH, model_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "71a1c92b-9275-4d96-a282-d8f406725d8b",
    "theme": {
     "71a1c92b-9275-4d96-a282-d8f406725d8b": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "71a1c92b-9275-4d96-a282-d8f406725d8b",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
