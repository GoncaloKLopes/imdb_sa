{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import settings as s\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import torch.optim as O\n",
    "import torch.nn as nn\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from model import BinarySARNN\n",
    "from configs import *\n",
    "from utils import dir_to_csv, tokenize, binary_accuracy, epoch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_path = os.path.join(s.DATASET_PATH, s.TRAIN_DIR)\n",
    "test_files_path = os.path.join(s.DATASET_PATH, s.TEST_DIR)\n",
    "dataset_path = os.path.join(s.DATA_DIR, s.CSV)\n",
    "\n",
    "embeddings_path = os.path.join(s.DATASET_PATH, s.EMBEDDINGS_FILE)\n",
    "vocab_path = os.path.join(s.DATA_DIR, s.VOCAB_FILE)\n",
    "\n",
    "model_config = RNN_CONFIG1\n",
    "train_config = TRAIN_CONFIG3\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists, skipping creation...\n",
      "Loading dataset...\n",
      "Training set successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# create train set\n",
    "dataset_paths = [train_files_path, test_files_path]\n",
    "dir_to_csv(s.CSV, dataset_paths)\n",
    "\n",
    "REVIEW = torchtext.data.Field(tokenize=tokenize, lower=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = torchtext.data.TabularDataset(path=dataset_path, format=\"CSV\",\n",
    "                                      fields=[(\"review\", REVIEW),\n",
    "                                              (\"label\", LABEL)],\n",
    "                                      csv_reader_params={\"delimiter\": \" \"})\n",
    "\n",
    "train, val, test = dataset.split(split_ratio=[0.7, 0.2, 0.1])\n",
    "\n",
    "\n",
    "train_iter = torchtext.data.Iterator(train, model_config.batch_size, device=device)\n",
    "val_iter = torchtext.data.Iterator(val, model_config.batch_size, device=device)\n",
    "\n",
    "REVIEW.build_vocab(train)\n",
    "print(\"Training set successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word embeddings...\n",
      "Word embeddings successfully loaded.\n",
      "\n",
      "vocabulary file already exists, skipping creation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load word embeddings\n",
    "print(\"Loading word embeddings...\")\n",
    "embeddings = KeyedVectors.load_word2vec_format(embeddings_path, binary=False,\n",
    "                                               unicode_errors='ignore')\n",
    "print(\"Word embeddings successfully loaded.\\n\")\n",
    "\n",
    "vocab = embeddings.vocab\n",
    "if not os.path.isfile(vocab_path):\n",
    "    print(\"Vocabulary file not present, creating...\")\n",
    "    with open(vocab_path, \"wb+\") as vf:\n",
    "        pickle.dump(vocab, vf)\n",
    "    print(\"Done.\\n\")\n",
    "else:\n",
    "    print(\"vocabulary file already exists, skipping creation...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarySARNN(\n",
       "  (embed): Embedding(168994, 300)\n",
       "  (rnn): RNN(300, 64)\n",
       "  (hidden_to_label): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set model configurations\n",
    "model_config.vocab_size = len(embeddings.vocab)\n",
    "model_config.d_embed = embeddings.vector_size\n",
    "\n",
    "model = BinarySARNN(model_config)\n",
    "model.embed.weight.data.copy_(torch.from_numpy(embeddings.vectors))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Config\n",
      "============\n",
      "d_hidden = 64\n",
      "vocab_size = 168994\n",
      "d_embed = 300\n",
      "batch_size = 64\n",
      "n_layers = 1\n",
      "nonlin = tanh\n",
      "dropout = 0\n",
      "bidir = False\n",
      "\n",
      "Train Config\n",
      "=============\n",
      "criterion = <class 'torch.nn.modules.loss.CrossEntropyLoss'>\n",
      "optimizer = <class 'torch.optim.adagrad.Adagrad'>\n",
      "optimizer args = {}\n",
      "epochs = 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set training configuration\n",
    "criterion = train_config.criterion()\n",
    "criterion.to(device)\n",
    "\n",
    "opt = train_config.optimizer(model.parameters(), **train_config.o_kwargs)\n",
    "\n",
    "print(str(model_config) + \"\\n\")\n",
    "print(str(train_config) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 32s\n",
      "\tTrain Loss: 0.695 | Train Acc: 57.14%\n",
      "\t Val. Loss: 0.693 |  Val. Acc: 49.25%\n",
      "Best Epoch -> 01\n",
      "Epoch: 02 | Epoch Time: 3m 6s\n",
      "\tTrain Loss: 0.688 | Train Acc: 55.36%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 49.29%\n",
      "Best Epoch -> 02\n",
      "Epoch: 03 | Epoch Time: 4m 40s\n",
      "\tTrain Loss: 0.710 | Train Acc: 35.71%\n",
      "\t Val. Loss: 0.693 |  Val. Acc: 49.49%\n",
      "Best Epoch -> 03\n",
      "Epoch: 04 | Epoch Time: 6m 13s\n",
      "\tTrain Loss: 0.691 | Train Acc: 57.14%\n",
      "\t Val. Loss: 0.695 |  Val. Acc: 49.27%\n",
      "Best Epoch -> 03\n",
      "Epoch: 05 | Epoch Time: 7m 44s\n",
      "\tTrain Loss: 0.714 | Train Acc: 50.00%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 49.05%\n",
      "Best Epoch -> 03\n"
     ]
    }
   ],
   "source": [
    "iterations = 0\n",
    "start = time.time()\n",
    "best_val_acc = -1\n",
    "val_every = 100\n",
    "train_iter.repeat = False\n",
    "best_epoch = 1\n",
    "\n",
    "model_fname = f\"{model_config.id}|{train_config.id}.pt\"\n",
    "\n",
    "for epoch in range(train_config.epochs):\n",
    "    train_iter.init_epoch()\n",
    "\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iter):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        iterations += 1\n",
    "        #forward pass\n",
    "        answer = model(batch.review)\n",
    "        \n",
    "        #calculate accuracy in current batch\n",
    "        train_acc = binary_accuracy(torch.max(answer, 1).values, batch.label.float()).item()\n",
    "        #calculate loss\n",
    "        loss = criterion(answer, batch.label)\n",
    "\n",
    "        #backpropagate, calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #update model parameters\n",
    "        opt.step()\n",
    "        \n",
    "    #evaluate\n",
    "    model.eval()\n",
    "    val_iter.init_epoch()\n",
    "    \n",
    "    epoch_loss, epoch_acc = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for val_batch_idx, val_batch in enumerate(val_iter):\n",
    "            answer = model(val_batch.review)\n",
    "            epoch_acc += binary_accuracy(torch.max(answer, 1).values, val_batch.label.float()).item()\n",
    "            epoch_loss += criterion(answer, val_batch.label)\n",
    "\n",
    "    epoch_loss /= len(val_iter)\n",
    "    epoch_acc /= len(val_iter)\n",
    "\n",
    "    if epoch_acc > best_val_acc:\n",
    "        best_val_acc = epoch_acc\n",
    "        torch.save(model.state_dict(), os.path.join(s.MODELS_PATH, model_fname))\n",
    "        best_epoch = epoch\n",
    "                \n",
    "    epoch_mins, epoch_secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\")\n",
    "    print(f\"\\tTrain Loss: {loss:.3f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f'\\t Val. Loss: {epoch_loss:.3f} |  Val. Acc: {epoch_acc*100:.2f}%')\n",
    "print(f'Best Epoch -> {best_epoch+1:02}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchtext.data.dataset.Dataset"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1991483904"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1424389632"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "71a1c92b-9275-4d96-a282-d8f406725d8b",
    "theme": {
     "71a1c92b-9275-4d96-a282-d8f406725d8b": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "71a1c92b-9275-4d96-a282-d8f406725d8b",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
